{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from parametrization import ParamHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../python/')\n",
    "import prediction_utils.rg_visu as rgv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_rc = {'lines.linewidth': 5,'lines.markersize': 20}              \n",
    "sns.set_context(\"paper\", rc = paper_rc, font_scale = 4.25)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_palette = sns.color_palette(\"Set2\", 8)\n",
    "m_palette = sns.color_palette(['#5cd65c','#ff6666','#ff944d'])\n",
    "custom_palette = m_palette + custom_palette\n",
    "#sns.palplot(custom_palette)\n",
    "sns.set_palette(m_palette + custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = ParamHelper(\"../../pipelines/USOpen.json\", \"ipython/experiments/uso_predict_player.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_media_nodes = ph.get(\"exclude_media_nodes\")\n",
    "include_only_players = ph.get(\"include_only_players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_root_dir = ph.get(\"uso_root_dir\")\n",
    "use_binary_labels = ph.get(\"use_binary_labels\")\n",
    "FIRST_SNAPSHOT = ph.get(\"eval_first_snapshot\")\n",
    "LAST_SNAPSHOT = ph.get(\"eval_last_snapshot\")\n",
    "use_c_ndcg = ph.get(\"use_cumulative_ndcg\")\n",
    "N_THREADS = ph.get(\"num_of_threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_postfix = \"_binary%s\" % use_binary_labels\n",
    "experiment_path = rg_root_dir + \"/daily_in_advance/\"\n",
    "tennis_players_source_path = rg_root_dir + \"/tennis_players%s/\" % dir_postfix\n",
    "original_experiment_path = experiment_path + \"/tennis_players%s_copied\" % dir_postfix\n",
    "similarity_root = experiment_path + \"similarity_metrics%s\" % dir_postfix\n",
    "prediction_experiment_path = \"../../data/centrality_scores/usopen_epoch_t505_d3600/original/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_size = 30\n",
    "num_of_days = ph.get(\"num_of_days\")\n",
    "num_of_intervals = num_of_days*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tennis_players_source_path,original_experiment_path,prediction_experiment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load included/excluded nodes (media accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_accounts_file_path = \"%s/recoded_media_accounts.txt\" % rg_root_dir\n",
    "player_accounts_file_path = \"%s/recoded_player_accounts.txt\" % tennis_players_source_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_only_players:\n",
    "    raise RuntimeError(\"Not supported option!\")\n",
    "elif exclude_media_nodes:\n",
    "    raise RuntimeError(\"Not supported option!\")\n",
    "else:\n",
    "    sim_res_folder = similarity_root + \"/results_with_media_nodes/\"\n",
    "    excluded_accounts = None\n",
    "    included_accounts = None\n",
    "\n",
    "img_dir = sim_res_folder + \"/img_from%i_to%i\" % (FIRST_SNAPSHOT, LAST_SNAPSHOT)\n",
    "print(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in (experiment_path, sim_res_folder, img_dir):\n",
    "    if not os.path.exists(p):\n",
    "        os.makedirs(p)\n",
    "        print(\"Directory was created: %s\" % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other parameters for similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_folders = ph.get(\"score_folders\")\n",
    "print(score_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = range(0,num_of_days) # eval all days\n",
    "print(days)\n",
    "print(num_of_intervals, num_of_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy tennis player score files to all directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interval_bounds(lookback_size=2*24):\n",
    "    interval_bounds = []\n",
    "    for day_idx in days:\n",
    "        upper_bound = (day_idx+1)*24\n",
    "        lower_bound = upper_bound - lookback_size\n",
    "        interval_subset = [max(0,lower_bound),upper_bound]\n",
    "        interval_bounds += [(day_idx,interval_subset)]\n",
    "    return interval_bounds\n",
    "\n",
    "def duplicate_label_files(interval_bounds):\n",
    "    for day_idx, bounds in interval_bounds:\n",
    "        target_folder = \"%s/%i\" % (original_experiment_path, day_idx)\n",
    "        if not os.path.exists(target_folder):\n",
    "            os.makedirs(target_folder)\n",
    "        full_src_file = \"%s/players_%i.csv\" % (tennis_players_source_path, day_idx)\n",
    "        for i in range(bounds[0],bounds[1]):\n",
    "            dest = \"%s/players_%i.csv\" % (target_folder, i)\n",
    "            shutil.copy(full_src_file, dest)\n",
    "        print(\"Labels for the %ith day were duplicated!\" % day_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interval_bounds = get_interval_bounds(lookback_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_label_files(interval_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_id = ph.get(\"metric_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate prediction similarities ###\n",
    "\n",
    "import evaluation_utils.eval_utils as eu\n",
    "\n",
    "def is_enabled_by_filter(score, filter_keys):\n",
    "    if filter_keys != None:\n",
    "        is_enabled = False\n",
    "        for f_key in filter_keys:\n",
    "            if f_key in score:\n",
    "                is_enabled = True\n",
    "                break\n",
    "    else:\n",
    "        is_enabled = True\n",
    "    return is_enabled\n",
    "\n",
    "def load_or_calculate_prediction_result(input_path_prefixes, score, met, intervals, similarity_result_folder, excluded_indices, restricted_indices, n_threads):\n",
    "    if not os.path.exists(similarity_result_folder):\n",
    "        os.makedirs(similarity_result_folder)\n",
    "    similarity_result_file = \"%s/%s.txt\" % (similarity_result_folder,met)\n",
    "    if os.path.exists(similarity_result_file):\n",
    "        res = list(np.loadtxt(similarity_result_file))\n",
    "        print(\"Results were loaded from file: %s\" % similarity_result_file)\n",
    "    else:\n",
    "        res = eu.calculate_measure_for_days(input_path_prefixes, measure_type=met, days=intervals, is_sequential=False, excluded_indices=excluded_indices, restricted_indices=restricted_indices, n_threads=n_threads)\n",
    "        np.savetxt(similarity_result_file,res)\n",
    "        print(\"%s: '%s' was calculated.\" % (score, met))\n",
    "    return res\n",
    "\n",
    "def calculate_metrics_for_prediction(similarity_map, measure_id, score_folders, interval_bounds, experiment_paths, similarity_result_folder, excluded_indices=None, restricted_indices=None, filter_keys=None, n_threads=1):\n",
    "    similarity_map[measure_id] = {}\n",
    "    for day_idx, _ in interval_bounds:\n",
    "        similarity_map[measure_id][day_idx] = {}\n",
    "    for score in score_folders:\n",
    "        if measure_id == score.split(\"_\")[0]:\n",
    "            if not is_enabled_by_filter(score, filter_keys):\n",
    "                continue\n",
    "            if not os.path.exists(similarity_result_folder):\n",
    "                os.makedirs(similarity_result_folder)\n",
    "            for day_idx, bound in interval_bounds:\n",
    "                input_path_prefixes = []\n",
    "                input_path_prefixes.append(\"%s/%i/players\" %  (experiment_paths[0],day_idx)) # label prefix\n",
    "                input_path_prefixes.append(\"%s/%s/%s\" % (experiment_paths[1], score, measure_id if measure_id != \"nbm\" else \"ndm\")) # prediction file prefix\n",
    "                similarity_res_dir = \"%s/%i/%s\" % (similarity_result_folder, day_idx, score)\n",
    "                similarity_map[measure_id][day_idx][score] = load_or_calculate_prediction_result(input_path_prefixes, score, metric_id, range(bound[0],bound[1]), similarity_res_dir, excluded_indices, restricted_indices, n_threads)\n",
    "    print(\"prediction analysis was FINISHED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_results, score_stat_results = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_paths = [original_experiment_path, prediction_experiment_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OnlineRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olr_filters = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"olr\", score_folders, interval_bounds, experiment_paths, sim_res_folder, filter_keys=olr_filters, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Indegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"olid\", score_folders, interval_bounds, experiment_paths, sim_res_folder, filter_keys=olr_filters, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"tpr\", score_folders, interval_bounds, experiment_paths, sim_res_folder, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"spr\", score_folders, interval_bounds, experiment_paths, sim_res_folder, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Indegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"indeg\", score_folders, interval_bounds, experiment_paths, sim_res_folder, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Negative beta-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"nbm\", score_folders, interval_bounds, experiment_paths, sim_res_folder, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Harmonic centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate_metrics_for_prediction(prediction_results, \"hc\", score_folders, interval_bounds, experiment_paths, sim_res_folder, excluded_indices=excluded_accounts, restricted_indices=included_accounts, n_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_metric_id = metric_id\n",
    "visu_metric_id = visu_metric_id.upper()\n",
    "visu_metric_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markers = [\"s\",\"*\",\"o\",\"^\",\"v\",\">\",\"D\",]\n",
    "\n",
    "def pred_perf_plot(score_visu_list,day_idx,offset=0):\n",
    "    l_bound, u_bound = interval_bounds[day_idx-offset][1][0], interval_bounds[day_idx-offset][1][1]\n",
    "    x = range(0,u_bound-l_bound)\n",
    "    visu_args = []\n",
    "    for i,score in enumerate(score_visu_list):\n",
    "        score_pref = score.split(\"_\")[0]\n",
    "        m = markers[i % len(markers)]\n",
    "        y = prediction_results[score_pref][day_idx][score]\n",
    "        visu_args += [x,y,\"%s-\" % m]\n",
    "    res = plt.plot(*visu_args)\n",
    "    x_ticks = list(reversed(-np.array(range(0,len(y)+1,5))))\n",
    "    plt.xticks(range(0,u_bound-l_bound,5),x_ticks)#,rotation=\"vertical\")\n",
    "    return res\n",
    "\n",
    "def get_cumulative_performance(df, metric_id, first_snapshot=None, last_snapshot=None):\n",
    "    print(len(df))\n",
    "    if first_snapshot == None:\n",
    "        first_snapshot = df[\"snapshot\"].min()\n",
    "    else:\n",
    "        df = df[df[\"snapshot\"] >= first_snapshot]\n",
    "    if last_snapshot == None:\n",
    "        last_snapshot = df[\"snapshot\"].max()\n",
    "    else:\n",
    "        df = df[df[\"snapshot\"] <= last_snapshot]\n",
    "    print(len(df))\n",
    "    cumulative_parts = []\n",
    "    for max_snapshot in range(first_snapshot, last_snapshot+1):\n",
    "        tmp_df = df[df[\"snapshot\"] <= max_snapshot]\n",
    "        aggr_perf_df = tmp_df.groupby(by=[\"score\",\"day\"])[metric_id].sum().reset_index()\n",
    "        aggr_perf_df[metric_id] = aggr_perf_df[metric_id] / (max_snapshot - first_snapshot + 1.0)\n",
    "        aggr_perf_df[\"snapshot\"] = max_snapshot\n",
    "        cumulative_parts.append(aggr_perf_df)\n",
    "    return pd.concat(cumulative_parts)\n",
    "\n",
    "def visu_pred_perf_per_day(score_visu_list, days, offset=0):\n",
    "    print(days)\n",
    "    num_plots = len(days)\n",
    "    n_rows, n_cols = num_plots // 2 + 1, 2\n",
    "    print(n_rows, n_cols, num_plots)\n",
    "    fig = plt.figure(figsize=(n_cols*10,n_rows*5))\n",
    "    lines = None\n",
    "    for i in range(num_plots):\n",
    "        plt.subplot(n_rows,n_cols,i+1)\n",
    "        lines = pred_perf_plot(score_visu_list,days[i],offset=offset)\n",
    "        plt.ylim((0.0,1.0))\n",
    "        plt.ylabel(visu_metric_id)\n",
    "        plt.title(dates[i])\n",
    "    detailed_relabel = ph.get(\"is_detailed_relabel\")\n",
    "    fig.legend(lines,tuple([rgv.relabel(score,detailed_relabel) for score in score_visu_list]),(0.55,0.065))\n",
    "    plt.savefig(img_dir + \"/%s/detailed_%s.png\" % (ph.get(\"img_dir\"),metric_id))   \n",
    "        \n",
    "def visu_mean_behaviour(visu_index_list,day_indexes,first_snapshot=FIRST_SNAPSHOT,last_snapshot=LAST_SNAPSHOT,pref=\"mixed\",metric=visu_metric_id,title_text=\"\",ci_val=0.5):\n",
    "    time_series = []\n",
    "    dir_name = img_dir + \"/\" + ph.get(\"img_dir\")\n",
    "    if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "    for score in visu_index_list:\n",
    "        if pref != \"mixed\" and pref not in score:\n",
    "            continue\n",
    "        score_pref = score.split(\"_\")[0]\n",
    "        for day_idx in days:\n",
    "            perf_values = prediction_results[score_pref][day_idx][score]\n",
    "            interval_idx = list(reversed(-np.array(range(1,len(perf_values)+1))))\n",
    "            time_series += list(zip([score for i in interval_idx],[day_idx for i in interval_idx],interval_idx,perf_values))\n",
    "    if len(time_series) > 0:\n",
    "        time_series_df = pd.DataFrame(time_series,columns=[\"score\",\"day\",\"snapshot\",metric])\n",
    "        rgv.extract_params(time_series_df)\n",
    "        time_series_df.to_csv(\"%s/full_table_%s_%s.csv\" % (dir_name,pref,visu_metric_id), sep=\";\", index=False)\n",
    "        if use_c_ndcg:\n",
    "            time_series_df = get_cumulative_performance(time_series_df, metric, first_snapshot=first_snapshot, last_snapshot=last_snapshot)\n",
    "            tmp_metric = \"cumulative_%s\" % metric\n",
    "            time_series_df[tmp_metric] = time_series_df[metric]\n",
    "        else:\n",
    "            time_series_df = time_series_df[(time_series_df[\"snapshot\"] >= first_snapshot) & (time_series_df[\"snapshot\"] <= last_snapshot)]\n",
    "            tmp_metric = metric\n",
    "        detailed_relabel = False#ph.get(\"is_detailed_relabel\")\n",
    "        time_series_df[\"score\"] = time_series_df[\"score\"].apply(lambda x: rgv.relabel(x,detailed_relabel))\n",
    "        print(len(time_series_df))\n",
    "        time_series_df = time_series_df[time_series_df[\"day\"].isin(day_indexes)]\n",
    "        print(len(time_series_df))\n",
    "        plt.figure(figsize=(22,14))\n",
    "        score_vals = time_series_df[\"score\"].unique()\n",
    "        for i,val in enumerate(score_vals):\n",
    "            c, m = custom_palette[i % len(custom_palette)], markers[i % len(markers)]\n",
    "            sns.tsplot(data=time_series_df[time_series_df[\"score\"]==val], time=\"snapshot\", unit=\"day\", condition=\"score\", value=tmp_metric, ci=ci_val, color=c, marker=m)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.savefig(\"%s/mean_%s_%s.png\" % (dir_name,pref,tmp_metric))\n",
    "        if not use_c_ndcg:\n",
    "            out_df = time_series_df.groupby(\"score\")[tmp_metric].mean().reset_index().sort_values(tmp_metric, ascending=False)\n",
    "            out_df.to_csv(\"%s/mean_%s_%s.csv\" % (dir_name,pref,tmp_metric), sep=\"\\t\", index=False, header=False)\n",
    "            return out_df\n",
    "    else:\n",
    "        print(\"No data to visualize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select subset of days for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#first_day_idx = 1 # 2017-08-22\n",
    "#last_day_index = num_of_days # 2017-09-10\n",
    "day_indexes = list(range(1,5)) + list(range(7,num_of_days)) # from 2017-08-22 to 2017-09-10 (excluding: 2017-08-26 and 2017-08-27)\n",
    "print(day_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from 2017-08-22 to 2017-09-10 (excluding: 2017-08-26 and 2017-08-27)\n",
    "day_indexes = list(range(15,num_of_days)) # last 6 days\n",
    "#day_indexes = list(range(1,5)) # first 4 days (qualidfications)\n",
    "print(day_indexes)\n",
    "\n",
    "dates = [\"2017-08-%.2i\" % i for i in range(21,32)]\n",
    "dates += [\"2017-09-%.2i\" % i for i in range(1,11)]\n",
    "dates = [dates[i] for i in day_indexes]\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "day_indexes = list(range(0,num_of_days))\n",
    "print(day_indexes)\n",
    "\n",
    "dates = [\"2017-08-%.2i\" % i for i in range(28,32)]\n",
    "dates += [\"2017-09-%.2i\" % i for i in range(1,11)]\n",
    "dates = [dates[i] for i in day_indexes]\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OnlineRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    title_text = ph.get(\"title_text\")\n",
    "except:\n",
    "    title_text = \"\"\n",
    "\n",
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"olr\", title_text=title_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Indegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"olid\", title_text=title_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"tpr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"spr\", title_text=\"of Static PageRank models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"indeg\", title_text=\"of Static Indegree models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative beta_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"nbm\", title_text=\"of Static Negative beta-measure models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonic centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes, pref=\"hc\", title_text=\"of Static Harmonic centrality models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import matplotlib\n",
    "\n",
    "SMALL_SIZE = 26\n",
    "MEDIUM_SIZE = 26\n",
    "BIGGER_SIZE = 28\n",
    "\n",
    "matplotlib.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "matplotlib.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "matplotlib.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "matplotlib.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "matplotlib.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "matplotlib.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "matplotlib.rc('figure', titlesize=BIGGER_SIZE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visu_mean_behaviour(score_folders, day_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paper_rc = {'lines.linewidth': 3,'lines.markersize': 10}              \n",
    "sns.set_context(\"paper\", rc = paper_rc, font_scale = 3)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_pred_perf_per_day(score_folders, day_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
