{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, shutil, random\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"../python/\")\n",
    "import concept_drift.graph_generator as gg\n",
    "import concept_drift.experiment_utils as ceu\n",
    "import centrality_utils.temporal_pagerank as tprc\n",
    "import centrality_utils.temporal_katz_computer as tkc\n",
    "import simulator_utils.graph_simulator as gsim\n",
    "from centrality_utils.base_computer import link2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "cmap = \"coolwarm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_title = {\n",
    "    \"facebook\":\"Facebook\",\n",
    "    \"students\":\"Students\",\n",
    "    \"tumblr\":\"Tumblr\",\n",
    "    \"enron\":\"Enron\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_score_dir = \"../data/polina_graphs/centrality_measures/\"\n",
    "fig_root = \"../results/concept_drift/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"students\"\n",
    "#mode = \"enron\"\n",
    "#mode = \"facebook\"\n",
    "#mode = \"tumblr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "n_sub = 400\n",
    "delta = 50\n",
    "iters = 10000\n",
    "max_iter = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sampling \"temporal\" edges from a random graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) Generate random graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gg.weighted_DiGraph(n, mode = mode, data_prefix=\"../data/polina_graphs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_order = list(G.nodes())\n",
    "E = G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.) Katz index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Katz-index damping factor\n",
    "\n",
    "   * If Katz diverges then exclude the damping factor from the experiments!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "katz_damping = [0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# katz\n",
    "valid_katz_damping = []\n",
    "katz_values = []\n",
    "for kd in katz_damping:\n",
    "    print(kd)\n",
    "    try:\n",
    "        katz = nx.katz_centrality(G,alpha=kd,max_iter=max_iter,tol=0.001)\n",
    "        katz_scores = [katz[n] for n in n_order]\n",
    "        katz_values.append(katz_scores)\n",
    "        valid_katz_damping.append(kd)\n",
    "    except nx.PowerIterationFailedConvergence:\n",
    "        print(\"Convergence failed for beta=%.3f\" % kd)\n",
    "        continue\n",
    "    except:\n",
    "        raise\n",
    "# divergent katz damping is excluded\n",
    "katz_damping = valid_katz_damping\n",
    "print(katz_damping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii.) Sampling temporal edges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define number of sampled edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delta,iters, n_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_1 = random.sample(n_order, n_sub)\n",
    "samples.append(ceu.get_stream(G=G, iters=iters, katz_alphas=katz_damping, katz_max_iter=max_iter, node_sample=nodes_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_2 = random.sample(n_order, n_sub)\n",
    "G = gg.change_weights(G)\n",
    "samples.append(ceu.get_stream(G=G, iters=iters, katz_alphas=katz_damping, katz_max_iter=max_iter, node_sample=nodes_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_3 = random.sample(n_order, n_sub)\n",
    "G = gg.change_weights(G)\n",
    "samples.append(ceu.get_stream(G=G, iters=iters, katz_alphas=katz_damping, katz_max_iter=max_iter, node_sample=nodes_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v.) Concatenate stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = []\n",
    "pr_items = []\n",
    "katz_items = [[] for i in range(len(katz_damping))]\n",
    "for stream_item, pr_item, katz_item in samples:\n",
    "    # append stream\n",
    "    stream += stream_item\n",
    "    print(len(stream_item))\n",
    "    # append pagerank\n",
    "    pr_vals = [pr_item.get(n, 0.0) for n in n_order]\n",
    "    pr_items.append((n_order,pr_vals))\n",
    "    # append katz\n",
    "    for j in range(len(katz_damping)):\n",
    "        # score can be zero (if node not occurred inthe sampled stream)\n",
    "        katz_vals =  [katz_item[j].get(n, 0.0) for n in n_order]\n",
    "        katz_items[j].append((n_order,katz_vals))\n",
    "len(stream), len(pr_items), len(katz_items), len(katz_items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.) Simulate models on sampled edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsim_params = []\n",
    "experiment_path = \"%s/%s\" % (centrality_score_dir, mode)\n",
    "time_type = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(experiment_path):\n",
    "    print(\"Deleting former files...\")\n",
    "    shutil.rmtree(experiment_path)\n",
    "    print(\"Files were deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = zip(*stream)\n",
    "edge_idx = range(len(stream))\n",
    "graph_data = np.array(list(zip(edge_idx, src, trg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.) Parametrize Temporal PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_params = []\n",
    "tpr_params += [tprc.TemporalPageRankParams(0.85,b) for b in [0.0,0.01,0.05,0.5,0.95]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tpr_params) > 0:\n",
    "    gsim_params.append(tprc.TemporalPageRankComputer(n_order,tpr_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b). Parametrize OnlineRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLR_BETA = 0.01\n",
    "c_values = [1.0,10.0,100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olr_params = []\n",
    "for c in c_values:\n",
    "    norm_factor = c / E\n",
    "    olr_params += [tkc.TemporalKatzParams(OLR_BETA, tkc.ExponentialWeighter(base=np.exp(-1),norm=1.0/norm_factor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(olr_params) > 0:\n",
    "    gsim_params.append(tkc.TemporalKatzComputer(n_order,olr_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for olr_item in olr_params:\n",
    "    print(olr_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.) Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries, eval_snapshots = [], []\n",
    "for i in range(delta,len(stream)+delta,delta):\n",
    "    boundaries.append(i)\n",
    "    eval_snapshots.append(-1+i/delta)\n",
    "len(boundaries), len(eval_snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gsim_obj = gsim.OnlineGraphSimulator(graph_data, time_type=time_type, verbose=False)\n",
    "experiment_graph_stats = gsim_obj.run_with_boundaries(gsim_params,boundaries,experiment_path, max_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_concept_drift(ground_truth, tpr_items, olr_items, legends, corr_type=\"Weighted Kendall-tau\"):\n",
    "    markers = [\"--\",\"-\",\"-.\",\":\"]\n",
    "    prefixes, corrs = [], []\n",
    "    #tpr\n",
    "    for tpr_item in tpr_items:\n",
    "        tpr_prefix = \"%s/original/%s/tpr\" % (experiment_path, str(tpr_item))\n",
    "        prefixes.append(tpr_prefix)\n",
    "        corrs.append(ceu.get_correlations(tpr_prefix, eval_snapshots, ground_truth))\n",
    "    #olr\n",
    "    for olr_item in olr_items:\n",
    "        olr_prefix = \"%s/original/%s/tk\" % (experiment_path, str(olr_item))\n",
    "        prefixes.append(olr_prefix)\n",
    "        corrs.append(ceu.get_correlations(olr_prefix, eval_snapshots, ground_truth))\n",
    "    #plot\n",
    "    visu_records = list(zip(prefixes, corrs))\n",
    "    plt.figure(figsize=(18,5))\n",
    "    shift = int(len(eval_snapshots)/6)\n",
    "    x = list(range(0,len(eval_snapshots),shift))\n",
    "    ticks = [val * delta for val in x]\n",
    "    for i, rec in enumerate(visu_records):\n",
    "        pref, corr = rec\n",
    "        if corr_type == \"pearson\":\n",
    "            plt.plot(corr[:,0],corr[:,1],markers[i],label=legends[i])\n",
    "        elif corr_type == \"spearman\":\n",
    "            plt.plot(corr[:,0],corr[:,2],markers[i],label=legends[i])\n",
    "        elif corr_type == \"kendall\":\n",
    "            plt.plot(corr[:,0],corr[:,3],markers[i],label=legends[i])\n",
    "        else:\n",
    "            plt.plot(corr[:,0],corr[:,4],markers[i],label=legends[i])\n",
    "    plt.ylabel(corr_type)\n",
    "    x_ticks_1 = [99,199,299,399,499,599]\n",
    "    x_ticks_2 = [5000,10000,15000,20000,25000,30000]\n",
    "    plt.xticks(x_ticks_1,x_ticks_2)\n",
    "    plt.xlabel(\"Number of temporal edges\")\n",
    "    plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_items = [tpr_params[3]]\n",
    "olr_indices = [0,1,2]\n",
    "olr_items = [olr_params[i] for i in olr_indices]\n",
    "legends = [\"Temporal PageRank\"]\n",
    "legends += [\"Temporal Katz: c=%i/E\" % c_values[i] for i in olr_indices]\n",
    "print(legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font=\"Palatino\",font_scale = 2.0)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) convergence to pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "show_concept_drift(pr_items, tpr_items, olr_items, legends)\n",
    "plt.title(ds_to_title[mode])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) convergence ot katz-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "show_concept_drift(katz_items[0], tpr_items, olr_items, legends)\n",
    "plt.title(ds_to_title[mode])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
